{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LATAM Reto Ingeniero de Datos - Farmers protest tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reto\n",
    "El reto consiste en responder tres preguntas claves para el an√°lisis de tweets sobre \"farmers protest\". Este reto permite ir m√°s all√° y dejar volar la imaginaci√≥n de forma que permita conocer los conocimientos y habilidades de los aspirantes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arquitectura\n",
    "\n",
    "Al ver el reto, el cual posee un archivo compreso cargado en un Google Drive p√∫blico y teniendo en cuenta el tiempo de desarrollo, la necesidad y las restricciones por el tipo de suscripci√≥n en el servicio de la nube; se plante√≥ una arquitectura h√≠brida desarrollada con Azure de la siguiente manera.\n",
    "\n",
    "![Texto alternativo](../imgs/ArquitecturaActual.png)\n",
    "\n",
    "Esta arquitectura posee un flujo de trabajo sobre el cual la ingesta de datos se vuelve m√°s automatizada por medio de un pipeline en el servicio de Azure Data Factory integrado con Github, el cual recibe un archivo JSON y lo convierte dependiendo de la necesidad en un CSV o un Parquet, esto es introducido como par√°metro al momento de correr el pipeline, esto permite una escalabilidad de la soluci√≥n a futuro.\n",
    "\n",
    "![Texto alternativo](../imgs/DataFactory.png)\n",
    "\n",
    "Los datos son almacenados tambi√©n en la nube posterior a esto en un Data Lake Storage Gen 2, un sistema de almacenamiento muy eficiente de Azure el cual permite bastantes tipos de datos con una gran eficiencia de lectura y escritura. All√≠ la data se separa en tres contenedores sobre los cuales el pipeline ir√° moviendo la informaci√≥n.\n",
    "\n",
    "![Texto alternativo](../imgs/DLSGen2.png)\n",
    "\n",
    "- Bussines: La fuente de datos cruda.\n",
    "- Landing: Los datos listos para ser procesados, en esta etapa ya el archivo JSON pasa a ser Parquet. (Ver mapeo de variables en la imagen posterior)\n",
    "- Work: Los datos resultado de las preguntas planteadas en el challenge.\n",
    "\n",
    "![Texto alternativo](../imgs/MapeoVariables.png)\n",
    "\n",
    "Finalmente, los datos son procesos en Python de forma local, donde se da respuesta a la soluci√≥n. Se intent√≥ realizar la soluci√≥n sobre Databricks, sin embargo, la conexi√≥n no fue posible entre Data Lake Storage Gen 2 y Databrick por limitaciones de la suscripci√≥n que se posee. Era necesaria una licencia Pay as you go. Debido a esto se plantea una arquitectura similar donde se emplee por completo una integraci√≥n en nube p√∫blica, es la siguiente, donde incluso se llega al punto de generar una visualizaci√≥n de la informaci√≥n por medio de Power BI, y pasando por una zona de validaci√≥n de datos (Curated), antes de poder ser consumida ya sea por un desarrollo de BA o BI.\n",
    "\n",
    "![Texto alternativo](../imgs/ArquitecturaPropuesta.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge\n",
    "Tener en cuenta que para realizar estas soluciones se trabaja con un archivo parquet creado a partir del mapeo de lo observado en el archivo inicial formato JSON, manteniendo la cantidad total de la informaci√≥n intacta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importe de librerias\n",
    "import pandas as pd\n",
    "from time import time\n",
    "\n",
    "# Se define ruta donde se encuentra la data del contenedor landing\n",
    "data_path = '../data/data.parquet'\n",
    "ansuwers_path = '../data/answers'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### q1_memory\n",
    "En este ejercicio se debe mostrar el top 10 de fechas donde m√°s tweets fueron realizados, con su respectiva cantidad optimizando la memoria. \n",
    "Para primero es importante recalcar que desde la ingesta y trasformaci√≥n de los datos desde Data Factory fue posible disminuir considerablemente el tama√±o del archivo, pasando de un JSON de 398MB a un Parquet de 73MB, posterior a esto, el c√≥digo optimiza la memoria cargando desde un inicio solo la columna con la cual se va a trabajar adem√°s de buscar usar la m√≠nima cantidad posible de variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo: 0.18770051002502441 seg\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(datetime.date(2021, 2, 12), 'RanbirS00614606'),\n",
       " (datetime.date(2021, 2, 13), 'MaanDee08215437'),\n",
       " (datetime.date(2021, 2, 17), 'RaaJVinderkaur'),\n",
       " (datetime.date(2021, 2, 16), 'jot__b'),\n",
       " (datetime.date(2021, 2, 14), 'rebelpacifist'),\n",
       " (datetime.date(2021, 2, 18), 'neetuanjle_nitu'),\n",
       " (datetime.date(2021, 2, 15), 'jot__b'),\n",
       " (datetime.date(2021, 2, 20), 'MangalJ23056160'),\n",
       " (datetime.date(2021, 2, 23), 'Surrypuria'),\n",
       " (datetime.date(2021, 2, 19), 'Preetm91')]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from q1_memory import q1_memory\n",
    "\n",
    "# soluci√≥n\n",
    "initial_time = time()\n",
    "result_q1 = q1_memory(data_path)\n",
    "print(f\"Tiempo: {time()-initial_time} seg\")\n",
    "\n",
    "result_q1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### q1_time\n",
    "En este ejercicio se debe mostrar el top 10 de fechas donde m√°s tweets fueron realizados, con su respectiva cantidad optimizando el tiempo. \n",
    "Para este ejercicio se plantea una lectura solo de las columnas necesarias de la data, adem√°s de eliminar los ciclos for del c√≥digo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo: 0.1103358268737793 seg\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(datetime.date(2021, 2, 12), 'RanbirS00614606'),\n",
       " (datetime.date(2021, 2, 13), 'MaanDee08215437'),\n",
       " (datetime.date(2021, 2, 17), 'RaaJVinderkaur'),\n",
       " (datetime.date(2021, 2, 16), 'jot__b'),\n",
       " (datetime.date(2021, 2, 14), 'rebelpacifist'),\n",
       " (datetime.date(2021, 2, 18), 'neetuanjle_nitu'),\n",
       " (datetime.date(2021, 2, 15), 'jot__b'),\n",
       " (datetime.date(2021, 2, 20), 'MangalJ23056160'),\n",
       " (datetime.date(2021, 2, 23), 'Surrypuria'),\n",
       " (datetime.date(2021, 2, 19), 'Preetm91')]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from q1_time import q1_time\n",
    "\n",
    "# soluci√≥n\n",
    "initial_time = time()\n",
    "result_q1 = q1_time(data_path)\n",
    "print(f\"Tiempo: {time()-initial_time} seg\")\n",
    "\n",
    "result_q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se guarda la respuesta\n",
    "df1 = pd.DataFrame(result_q1, columns=['Fecha', 'Cantidad'])\n",
    "df1.to_csv(f\"{ansuwers_path}/AnswerQ1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### q2_memory\n",
    "En este ejercicio se debe mostrar el top 10 de los emojis m√°s usados de los contenidos de los tweets con su respectiva cantidad, optimizando la memoria. \n",
    "Para esto se disminuy√≥ la cantidad de variables que se almacenen en memoria de forma significativa, este reto tiene una particularidad interesante comparado con el anterior el cual fue uno de los retos a nivel personal importantes aunque parezca simple, el hecho de disminuir la memoria teniendo en cuenta que es necesario realizar bucles sobre la tabla y adem√°s sobre el texto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo: 4.053999662399292 seg\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('üôè', 7286),\n",
       " ('üòÇ', 3072),\n",
       " ('üöú', 2972),\n",
       " ('|', 2429),\n",
       " ('‚úä', 2411),\n",
       " ('üåæ', 2363),\n",
       " ('üáÆ', 2096),\n",
       " ('üá≥', 2094),\n",
       " ('‚ù§', 1779),\n",
       " ('ü§£', 1668)]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from q2_memory import q2_memory\n",
    "\n",
    "# soluci√≥n\n",
    "initial_time = time()\n",
    "result_q2 = q2_memory(data_path)\n",
    "print(f\"Tiempo: {time()-initial_time} seg\")\n",
    "\n",
    "result_q2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### q2_time\n",
    "En este ejercicio se debe mostrar el top 10 de los emojis m√°s usados de los contenidos de los tweets con su respectiva cantidad, optimizando el tiempo. \n",
    "Al igual que el primer ejercicio, se busca disminuir la cantidad de ciclos en el proceso, adem√°s de segmentar un poco el c√≥digo, separando la funci√≥n de validaci√≥n de si el car√°cter es un emoji o no. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo: 4.150782108306885 seg\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('üôè', 7286),\n",
       " ('üòÇ', 3072),\n",
       " ('üöú', 2972),\n",
       " ('|', 2429),\n",
       " ('‚úä', 2411),\n",
       " ('üåæ', 2363),\n",
       " ('üáÆ', 2096),\n",
       " ('üá≥', 2094),\n",
       " ('‚ù§', 1779),\n",
       " ('ü§£', 1668)]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from q2_time import q2_time\n",
    "\n",
    "# soluci√≥n\n",
    "initial_time = time()\n",
    "result_q2 = q2_time(data_path)\n",
    "print(f\"Tiempo: {time()-initial_time} seg\")\n",
    "\n",
    "result_q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se guarda la respuesta\n",
    "df2 = pd.DataFrame(result_q1, columns=['Emoji', 'Cantidad'])\n",
    "df2.to_csv(f\"{ansuwers_path}/AnswerQ2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### q3_memory\n",
    "En este ejercicio se debe mostrar el top 10 de los usuarios mas mencionados en los tweets con su respectiva cantidad, optimizando la memoria. \n",
    "Se realiza un planteamiento igual a los mencionados en ejercicios anteriores, tengiendo en cuenta que la data al emplear un archivo parquet se va a optimizar bastante, la dantidad de datos no es muy grande para percibir cambios significativos en el uso de la memoria, adem√°s de poseer un script mas sencillo que los ejercicios apsados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo: 0.038260459899902344 seg\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('narendramodi', 1135),\n",
       " ('Kisanektamorcha', 985),\n",
       " ('RakeshTikaitBKU', 782),\n",
       " ('PMOIndia', 674),\n",
       " ('RaviSinghKA', 584),\n",
       " ('YouTube', 568),\n",
       " ('Tractor2twitr', 493),\n",
       " ('RahulGandhi', 460),\n",
       " ('DelhiPolice', 369),\n",
       " ('rihanna', 364)]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from q3_memory import q3_memory\n",
    "\n",
    "# soluci√≥n\n",
    "initial_time = time()\n",
    "result_q3 = q3_memory(data_path)\n",
    "print(f\"Tiempo: {time()-initial_time} seg\")\n",
    "\n",
    "result_q3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### q3_time\n",
    "En este ejercicio se debe mostrar el top 10 de los usuarios mas mencionados en los tweets con su respectiva cantidad, optimizando el tiempo. \n",
    "Se busca disminuir al maximo los bucles repetitivos sobre el dataframe, adem√°s de poseer una variable propia, diccionario para el almacenamiento de resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo: 0.022534847259521484 seg\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('narendramodi', 1135),\n",
       " ('Kisanektamorcha', 985),\n",
       " ('RakeshTikaitBKU', 782),\n",
       " ('PMOIndia', 674),\n",
       " ('RaviSinghKA', 584),\n",
       " ('YouTube', 568),\n",
       " ('Tractor2twitr', 493),\n",
       " ('RahulGandhi', 460),\n",
       " ('DelhiPolice', 369),\n",
       " ('rihanna', 364)]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from q3_time import q3_time\n",
    "\n",
    "# soluci√≥n\n",
    "initial_time = time()\n",
    "result_q3 = q3_time(data_path)\n",
    "print(f\"Tiempo: {time()-initial_time} seg\")\n",
    "\n",
    "result_q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se guarda la respuesta\n",
    "df3 = pd.DataFrame(result_q1, columns=['Usuario', 'Cantidad'])\n",
    "df3.to_csv(f\"{ansuwers_path}/AnswerQ3.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pruebas-ingreso",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
